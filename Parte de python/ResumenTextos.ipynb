{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RESUMENES DE TEXTO PARA EL DATASET NEWSPACE"
      ],
      "metadata": {
        "id": "rsOgAkr_D6UR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este notebook queremos intentar generar resumenes de los artículos que se encuentran en el DataSet analizado previamente en R.\n",
        "\n",
        "Para hacer este notebook nos hemos apoyado en este otro:\n",
        "\n",
        "- https://www.kaggle.com/code/midouazerty/text-summarizer-using-nlp-advanced\n",
        "\n"
      ],
      "metadata": {
        "id": "lkZSXWxwG8eS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El Resumen de Texto Automático es una aplicación del Procesamiento de Lenguaje Natural (NLP) con un gran potencial de impacto en nuestras vidas. Además, es uno de los problemas más desafiantes e interesantes en el campo del NLP.Consistente en generar un resumen breve y relevante a partir de diversos recursos de texto, como libros, artículos de noticias, publicaciones de blogs, documentos de investigación, correos electrónicos y tweets."
      ],
      "metadata": {
        "id": "ldYlfA55E5xK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para nuestro caso y según lo que aparece el notebook en el que nos hemos basado, vamos a utilizar un algoritmo que se llama TextRank que además es similar al que usan algunos modelos preentrenados como Bert o GPT los cuales también probaremos.\n",
        "\n",
        "El algoritmo TextRank se utiliza para resumir automáticamente textos. Es una técnica de procesamiento de lenguaje natural (NLP) que identifica las oraciones más importantes en un texto y las resume en un formato más conciso y significativo. Este algoritmo se basa en conceptos de grafos y análisis de texto para asignar puntajes de importancia a las oraciones según su relación con otras oraciones en el texto. Las oraciones con los puntajes más altos son seleccionadas para formar el resumen final."
      ],
      "metadata": {
        "id": "R_uK2-r-FmT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Librerias"
      ],
      "metadata": {
        "id": "Ik1oWWcMGyjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyreadr"
      ],
      "metadata": {
        "id": "A6tRJezUGecd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb1a406a-6de4-43ed-ff0b-2bb2a780d6bb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyreadr in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyreadr) (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadr) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadr) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadr) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadr) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadr) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsJ0jXR67WjE",
        "outputId": "3728779c-508d-4139-9549-8dc54b436cc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import re\n",
        "import nltk\n",
        "import pyreadr\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from textblob import TextBlob\n",
        "import string\n",
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "from statistics import mean\n",
        "from heapq import nlargest\n",
        "from wordcloud import WordCloud\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "punctuation = punctuation + '\\n' + '—' + '“' + ',' + '”' + '‘' + '-' + '’'\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepración"
      ],
      "metadata": {
        "id": "2ZdpeNFDQS5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En un principio quisimos importar el csv inicial donde se encontraba toda la información, pero tuvimos problemas con los separadores. Nuestro csv tenia como separadores la coma, y al parecer en el contenido de alguna noticia donde habia alguna coma, Python lo interpretaba como un seprador provacando que al final hubiese problemas con el número de columnas. Es por esto que decidimos importar mejor el rda.\n",
        "\n",
        "Por otra parte, también vimos que era una mejor opción, pues en el trabajo previo en R separamos en dos DataSets el conjunto en función de si tenía o no resumen. Además de que esta bastante limpio.\n",
        "\n",
        "Importamos el DataSet que previamente hicimos en R con los datos del DataSet SpaceNews que no tienen resumen. Para ello nos ayudamos de la libreria `pyread`"
      ],
      "metadata": {
        "id": "X1wt-67OQY2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Especifica la ruta de tu archivo RDA\n",
        "archivo_rda = \"datos_space_sin_extracto.rda\"\n",
        "\n",
        "# Usa la función read_r de pyreadr para cargar el archivo\n",
        "datos = pyreadr.read_r(archivo_rda)\n"
      ],
      "metadata": {
        "id": "Cgmd2vMP7-IB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora tenemos que pasar el DataSet a un DataFrame de Pandas para poder realizar operaciones en Python, para ello necesitamos saber las claves disponibles, que en teoría debería ser `datos_space_sin_extracto` que es el nombre que indicamos en R. Además, en nuestro caso solo tenemos una única key pues solo esta datos_space_sin_extracto, pero se podria dar el caso de que hubiese varias keys y tendriamos que seleccionar una de ellas."
      ],
      "metadata": {
        "id": "1Gp_ODq2QtqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar las claves disponibles\n",
        "print(datos.keys())\n",
        "\n",
        "# Elegir la clave correcta que contiene el DataFrame\n",
        "# Por ejemplo, si el DataFrame está bajo la clave \"df\", puedes hacer:\n",
        "df = datos[\"datos_space_sin_extracto\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N606iGZEDI6r",
        "outputId": "19904272-4145-4cf1-efbf-dff0bb5ead42"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['datos_space_sin_extracto'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para verificar que tenemos todo correctamente, imprimimos los primeros elementos e indicamos cuántas filas y columnas tiene el DataFrame."
      ],
      "metadata": {
        "id": "_BfEBdmkRvQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "\n",
        "# Obtener la cantidad de filas y columnas del DataFrame\n",
        "filas, columnas = df.shape\n",
        "\n",
        "print(\"Número de filas:\", filas)\n",
        "print(\"Número de columnas:\", columnas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImfYy81dE87P",
        "outputId": "f378fbaf-b95d-4100-91a1-e3e1014d7fd5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de filas: 1367\n",
            "Número de columnas: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algortimo de resumen"
      ],
      "metadata": {
        "id": "zIhqPl5nSF3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero vamos a crear un diccionario por si hay contracciones poder saber cual sería su forma normal. Por comodidad hemos cogido el mismo que habia en el notebook."
      ],
      "metadata": {
        "id": "aMPlNkejSIKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contractions_dict = {\n",
        "\"ain't\": \"am not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"doesn’t\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"don’t\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he'll've\": \"he will have\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"i'd\": \"i would\",\n",
        "\"i'd've\": \"i would have\",\n",
        "\"i'll\": \"i will\",\n",
        "\"i'll've\": \"i will have\",\n",
        "\"i'm\": \"i am\",\n",
        "\"i've\": \"i have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it'll've\": \"it will have\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she'll've\": \"she will have\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so is\",\n",
        "\"that'd\": \"that would\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they'll've\": \"they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what'll've\": \"what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who'll've\": \"who will have\",\n",
        "\"who's\": \"who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y’all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you'll've\": \"you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\",\n",
        "\"ain’t\": \"am not\",\n",
        "\"aren’t\": \"are not\",\n",
        "\"can’t\": \"cannot\",\n",
        "\"can’t’ve\": \"cannot have\",\n",
        "\"’cause\": \"because\",\n",
        "\"could’ve\": \"could have\",\n",
        "\"couldn’t\": \"could not\",\n",
        "\"couldn’t’ve\": \"could not have\",\n",
        "\"didn’t\": \"did not\",\n",
        "\"doesn’t\": \"does not\",\n",
        "\"don’t\": \"do not\",\n",
        "\"don’t\": \"do not\",\n",
        "\"hadn’t\": \"had not\",\n",
        "\"hadn’t’ve\": \"had not have\",\n",
        "\"hasn’t\": \"has not\",\n",
        "\"haven’t\": \"have not\",\n",
        "\"he’d\": \"he had\",\n",
        "\"he’d’ve\": \"he would have\",\n",
        "\"he’ll\": \"he will\",\n",
        "\"he’ll’ve\": \"he will have\",\n",
        "\"he’s\": \"he is\",\n",
        "\"how’d\": \"how did\",\n",
        "\"how’d’y\": \"how do you\",\n",
        "\"how’ll\": \"how will\",\n",
        "\"how’s\": \"how is\",\n",
        "\"i’d\": \"i would\",\n",
        "\"i’d’ve\": \"i would have\",\n",
        "\"i’ll\": \"i will\",\n",
        "\"i’ll’ve\": \"i will have\",\n",
        "\"i’m\": \"i am\",\n",
        "\"i’ve\": \"i have\",\n",
        "\"isn’t\": \"is not\",\n",
        "\"it’d\": \"it would\",\n",
        "\"it’d’ve\": \"it would have\",\n",
        "\"it’ll\": \"it will\",\n",
        "\"it’ll’ve\": \"it will have\",\n",
        "\"it’s\": \"it is\",\n",
        "\"let’s\": \"let us\",\n",
        "\"ma’am\": \"madam\",\n",
        "\"mayn’t\": \"may not\",\n",
        "\"might’ve\": \"might have\",\n",
        "\"mightn’t\": \"might not\",\n",
        "\"mightn’t’ve\": \"might not have\",\n",
        "\"must’ve\": \"must have\",\n",
        "\"mustn’t\": \"must not\",\n",
        "\"mustn’t’ve\": \"must not have\",\n",
        "\"needn’t\": \"need not\",\n",
        "\"needn’t’ve\": \"need not have\",\n",
        "\"o’clock\": \"of the clock\",\n",
        "\"oughtn’t\": \"ought not\",\n",
        "\"oughtn’t’ve\": \"ought not have\",\n",
        "\"shan’t\": \"shall not\",\n",
        "\"sha’n’t\": \"shall not\",\n",
        "\"shan’t’ve\": \"shall not have\",\n",
        "\"she’d\": \"she would\",\n",
        "\"she’d’ve\": \"she would have\",\n",
        "\"she’ll\": \"she will\",\n",
        "\"she’ll’ve\": \"she will have\",\n",
        "\"she’s\": \"she is\",\n",
        "\"should’ve\": \"should have\",\n",
        "\"shouldn’t\": \"should not\",\n",
        "\"shouldn’t’ve\": \"should not have\",\n",
        "\"so’ve\": \"so have\",\n",
        "\"so’s\": \"so is\",\n",
        "\"that’d\": \"that would\",\n",
        "\"that’d’ve\": \"that would have\",\n",
        "\"that’s\": \"that is\",\n",
        "\"there’d\": \"there would\",\n",
        "\"there’d’ve\": \"there would have\",\n",
        "\"there’s\": \"there is\",\n",
        "\"they’d\": \"they would\",\n",
        "\"they’d’ve\": \"they would have\",\n",
        "\"they’ll\": \"they will\",\n",
        "\"they’ll’ve\": \"they will have\",\n",
        "\"they’re\": \"they are\",\n",
        "\"they’ve\": \"they have\",\n",
        "\"to’ve\": \"to have\",\n",
        "\"wasn’t\": \"was not\",\n",
        "\"we’d\": \"we would\",\n",
        "\"we’d’ve\": \"we would have\",\n",
        "\"we’ll\": \"we will\",\n",
        "\"we’ll’ve\": \"we will have\",\n",
        "\"we’re\": \"we are\",\n",
        "\"we’ve\": \"we have\",\n",
        "\"weren’t\": \"were not\",\n",
        "\"what’ll\": \"what will\",\n",
        "\"what’ll’ve\": \"what will have\",\n",
        "\"what’re\": \"what are\",\n",
        "\"what’s\": \"what is\",\n",
        "\"what’ve\": \"what have\",\n",
        "\"when’s\": \"when is\",\n",
        "\"when’ve\": \"when have\",\n",
        "\"where’d\": \"where did\",\n",
        "\"where’s\": \"where is\",\n",
        "\"where’ve\": \"where have\",\n",
        "\"who’ll\": \"who will\",\n",
        "\"who’ll’ve\": \"who will have\",\n",
        "\"who’s\": \"who is\",\n",
        "\"who’ve\": \"who have\",\n",
        "\"why’s\": \"why is\",\n",
        "\"why’ve\": \"why have\",\n",
        "\"will’ve\": \"will have\",\n",
        "\"won’t\": \"will not\",\n",
        "\"won’t’ve\": \"will not have\",\n",
        "\"would’ve\": \"would have\",\n",
        "\"wouldn’t\": \"would not\",\n",
        "\"wouldn’t’ve\": \"would not have\",\n",
        "\"y’all\": \"you all\",\n",
        "\"y’all\": \"you all\",\n",
        "\"y’all’d\": \"you all would\",\n",
        "\"y’all’d’ve\": \"you all would have\",\n",
        "\"y’all’re\": \"you all are\",\n",
        "\"y’all’ve\": \"you all have\",\n",
        "\"you’d\": \"you would\",\n",
        "\"you’d’ve\": \"you would have\",\n",
        "\"you’ll\": \"you will\",\n",
        "\"you’ll’ve\": \"you will have\",\n",
        "\"you’re\": \"you are\",\n",
        "\"you’re\": \"you are\",\n",
        "\"you’ve\": \"you have\",\n",
        "}\n",
        "\n",
        "contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))"
      ],
      "metadata": {
        "id": "LtN1bBCbSVvn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con esta función queremos expandir la contracción en caso de que nos la encontremos, de ahí que previamente hubiesemos creado un diccionario con las contracciones y expansiones más comunes."
      ],
      "metadata": {
        "id": "klGGfFCbIbyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def expand_contractions(s, contractions_dict = contractions_dict):\n",
        "    def replace(match):\n",
        "        return contractions_dict[match.group(0)]\n",
        "    return contractions_re.sub(replace, s)"
      ],
      "metadata": {
        "id": "s1jt-VTbSfXR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta función terminamos de preprocesar los artículos, que aunque se haya hecho una buena limpieza y preprocesamiento en la parte de R aún queda por dar unas últimas pinceladas."
      ],
      "metadata": {
        "id": "HFP90lNMJRpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(article):\n",
        "    global article_sent\n",
        "\n",
        "    # Removing the contractions\n",
        "    article = article.apply(lambda x: expand_contractions(x))\n",
        "\n",
        "    # Stripping the possessives\n",
        "    article = article.apply(lambda x: x.replace(\"'s\", ''))\n",
        "    article = article.apply(lambda x: x.replace('’s', ''))\n",
        "    article = article.apply(lambda x: x.replace(\"\\'s\", ''))\n",
        "    article = article.apply(lambda x: x.replace(\"\\’s\", ''))\n",
        "\n",
        "    # Removing the Trailing and leading whitespace and double spaces\n",
        "    article = article.apply(lambda x: re.sub(' +', ' ',x))\n",
        "\n",
        "    # Copying the article for the sentence tokenization\n",
        "    article_sent = article.copy()\n",
        "\n",
        "    # Removing punctuations from the article\n",
        "    article = article.apply(lambda x: ''.join(word for word in x if word not in punctuation))\n",
        "\n",
        "    # Removing the Trailing and leading whitespace and double spaces again as removing punctuation might\n",
        "    # Lead to a white space\n",
        "    article = article.apply(lambda x: re.sub(' +', ' ',x))\n",
        "\n",
        "    # Removing the Stopwords\n",
        "    article = article.apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))\n",
        "\n",
        "    return article"
      ],
      "metadata": {
        "id": "Jq8B58oWSkfk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui queremos normalizar la frecuencia de las palabras que salen de la función `word_frequncy`"
      ],
      "metadata": {
        "id": "6NYCv-2CDgw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(li_word):\n",
        "    global normalized_freq\n",
        "    normalized_freq = []\n",
        "    for dictionary in li_word:\n",
        "        max_frequency = max(dictionary.values())\n",
        "        for word in dictionary.keys():\n",
        "            dictionary[word] = dictionary[word]/max_frequency\n",
        "        normalized_freq.append(dictionary)\n",
        "    return normalized_freq"
      ],
      "metadata": {
        "id": "lKpEak42Sn0V"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculamos la frecuencia de las palabras. Esto es verdad que lo hicimos en R, sin embargo es una información que aquí no tenemos por lo que tenemos que volver a calcular su frecuencia."
      ],
      "metadata": {
        "id": "PUia9QWxDscy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_frequency(article_word):\n",
        "    word_frequency = {}\n",
        "    li_word = []\n",
        "    for sentence in article_word:\n",
        "        for word in word_tokenize(sentence):\n",
        "            if word not in word_frequency.keys():\n",
        "                word_frequency[word] = 1\n",
        "            else:\n",
        "                word_frequency[word] += 1\n",
        "        li_word.append(word_frequency)\n",
        "        word_frequency = {}\n",
        "    normalize(li_word)\n",
        "    return normalized_freq"
      ],
      "metadata": {
        "id": "pIQtogaxSqQO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para realizar un buen resumen es necesario dar un Score a las oraciones, esto es con el objetivo de utilizar las oraciones que sean más importantes y que el resumen aporte información concisa y relevante. El Score se da después de tokenizar la oración."
      ],
      "metadata": {
        "id": "zjbcowpPEPiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_score(li):\n",
        "    global sentence_score_list\n",
        "    sentence_score = {}\n",
        "    sentence_score_list = []\n",
        "    for list_, dictionary in zip(li, normalized_freq):\n",
        "        for sent in list_:\n",
        "            for word in word_tokenize(sent):\n",
        "                if word in dictionary.keys():\n",
        "                    if sent not in sentence_score.keys():\n",
        "                        sentence_score[sent] = dictionary[word]\n",
        "                    else:\n",
        "                        sentence_score[sent] += dictionary[word]\n",
        "        sentence_score_list.append(sentence_score)\n",
        "        sentence_score = {}\n",
        "    return sentence_score_list"
      ],
      "metadata": {
        "id": "TaUrpKvnSsWg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizamos la oración que al igual que nos pasaba en la funcion para calcular la frecuencia, aquí tampoco disponemos de los tokens por lo que es necesario generalos de nuevo."
      ],
      "metadata": {
        "id": "EatuN58PECqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sent_token(article_sent):\n",
        "    sentence_list = []\n",
        "    sent_token = []\n",
        "    for sent in article_sent:\n",
        "        token = sent_tokenize(sent)\n",
        "        for sentence in token:\n",
        "            token_2 = ''.join(word for word in sentence if word not in punctuation)\n",
        "            token_2 = re.sub(' +', ' ',token_2)\n",
        "            sent_token.append(token_2)\n",
        "        sentence_list.append(sent_token)\n",
        "        sent_token = []\n",
        "    sentence_score(sentence_list)\n",
        "    return sentence_score_list"
      ],
      "metadata": {
        "id": "3Kvhs3BkStuy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generamos el resumen usando oraciones que tengan el mayor Score, en concreto vamos a especificar que esten en el 20% más alto."
      ],
      "metadata": {
        "id": "72WW-HG5Ej-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summary(sentence_score_OwO):\n",
        "    summary_list = []\n",
        "    for summ in sentence_score_OwO:\n",
        "        select_length = int(len(summ)*0.25)\n",
        "        summary_ = nlargest(select_length, summ, key = summ.get)\n",
        "        summary_list.append(\".\".join(summary_))\n",
        "    return summary_list"
      ],
      "metadata": {
        "id": "0blSXpUcSxnf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que estamos trabajando con la libreria Pandas queremos pasarlo todo a dicho formato."
      ],
      "metadata": {
        "id": "et90W2V5E9tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_series(art):\n",
        "    global dataframe\n",
        "    data_dict = {'article' : [art]}\n",
        "    dataframe = pd.DataFrame(data_dict)['article']\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "eGe75IhzSz2k"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último aquí, indicamos el orden en el que queremos que se ejecuten las funciones anteriores para el funcionamiento del algoritmo."
      ],
      "metadata": {
        "id": "NrWyljPpFIZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def article_summarize(artefact):\n",
        "\n",
        "    if type(artefact) != pd.Series:\n",
        "        artefact = make_series(artefact)\n",
        "\n",
        "    df = preprocessing(artefact)\n",
        "\n",
        "    word_normalization = word_frequency(df)\n",
        "\n",
        "    sentence_score_OwO = sent_token(article_sent)\n",
        "\n",
        "    summarized_article = summary(sentence_score_OwO)\n",
        "\n",
        "    return summarized_article"
      ],
      "metadata": {
        "id": "yqfa00XuS2GR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generamos los resúmenes para casi todos los artículos. No hemos podido generar para todos ya que al intentarlo nos daba un error de que nos pasabamos de límite, por lo que fuimos probando a mano hasta el máximo que no dejaba generar."
      ],
      "metadata": {
        "id": "XAbB7SJeJ62i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summaries = article_summarize(df['content'][0:1348])"
      ],
      "metadata": {
        "id": "XABV5T3iS78f"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"The Actual length of the article is : \", len(df['content'][0]))\n",
        "df['content'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "qN1CzRPdTtzJ",
        "outputId": "6f0d3a99-397c-41e0-98a0-e055be313236"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Actual length of the article is :  4585\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'paris — with a recent funding round and growing demand for its radio-frequency geolocation capabilities, hawkeye 360’s chief executive says the company has reached an “inflection point” on the path towards profitability and potentially going public. hawkeye 360 announced july 13  it raised $58 million in a series d-1 round  led by blackrock. the company said then that the funding would support development of new satellites and analytics products. the company has raised $368 million to date, said john serafini, chief executive of hawkeye 360, in an interview during world satellite business week here sept. 13. that round may also be the last private funding the company needs to raise. “provided that we execute against our revenue forecasts, which are conservative and we think we can do, we won’t need to raise additional private capital,” he said. profitability, he added, “is on the horizon for us,” but didn’t offer a specific timeline for achieving it. in a presentation at an investor conference a year ago,  serafini said the company was considering going public  though an initial public offering (ipo) of stock in two to three years. that is still the plan now, he said, although the timing will depend as much on market conditions as it will the state of the company. “the market being open or closed has a lot to do with it,” he said of the timing of an ipo, which he said remains likely two to three years out. “whether we can achieve the requisite milestones is the biggest issue,” such as achieving profitability and the right unit economics. “that’s what we can control and we’re rushing like heck to get to that spot.” the new funding and the growth of the business have put hawkeye 360 into a good position, he argued. “i would say we’re at an inflection point,” he said, from the funding to plans to launch additional satellites and development of analytics tools that leverage machine learning and artificial intelligence. “all of that in the next 12 to 18 months has got us in a great position.” governments remain the largest customers for hawkeye 360, which serafini said will likely be the case for the foreseeable future. that has included defense and intelligence applications as well as some civil and broader security applications, like tracking illegal fishing or deforestation. “one of the tenets we set the company up with was to focus on where the money is. the money in remote sensing is, ultimately, in defense and intelligence,” he said. “if you can’t service those customers, you’re not going to exist as a company.” that work has included work in ukraine since russia’s invasion more than a year and a half ago,  tracking sources of gps and other radio-frequency interference . serafini declined to go into details about the company’s work there, but he said the conflict has highlighted the importance of both commercial remote sensing capabilities in general as well as the need to work closely with the users of those capabilities. “throwing remote sensing data over a fence probably doesn’t lead to success,” he said. “one of the areas of growth for hawkeye is understanding the tactical intelligence, surveillance, reconnaissance requirements of our customers, and the networks and systems that they operate in, such that our data can flow into their existing systems as seamlessly as possible and produce another layer of valuable intelligence, not just drowning them in additional data.” that data comes from 21 satellites currently in orbit. six more are scheduled to launch later this year on a rocket lab electron from new zealand. the company’s long-term goal is to have 60 satellites, in 20 three-satellite clusters, which serafini said the company expects to achieve by 2025 or 2026. those satellites, built both by the space flight laboratory at the university of toronto institute for aerospace studies as well as hawkeye 360’s own facility in northern virginia, will be a mix of both its existing block 2 design and new block 3 design. the plans for block 3 are “very fluid,” he said, and could feature two different designs, a smaller one to focus on specific signals and a larger one to do “very advanced” work. hawkeye 360 also announced sept. 12 it promoted rob rainhart, the company’s chief operating officer since 2019, to president. “rob and i have been partners together for eight years,” serafini said. rainhart handles internal company operations, responsibilities he will continue as president. “he keeps the company running on time, and so it felt like the right time to make the move to promote him to president.”'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"The length of the summarized article is : \", len(summaries[0]))\n",
        "summaries[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "Gzs2jyRWT1A0",
        "outputId": "a5c94fea-c34e-430e-9625-ceee3dc2e492"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the summarized article is :  1723\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the company longterm goal is to have 60 satellites in 20 threesatellite clusters which serafini said the company expects to achieve by 2025 or 2026 those satellites built both by the space flight laboratory at the university of toronto institute for aerospace studies as well as hawkeye 360 own facility in northern virginia will be a mix of both its existing block 2 design and new block 3 design.the company has raised 368 million to date said john serafini chief executive of hawkeye 360 in an interview during world satellite business week here sept 13 that round may also be the last private funding the company needs to raise.one of the areas of growth for hawkeye is understanding the tactical intelligence surveillance reconnaissance requirements of our customers and the networks and systems that they operate in such that our data can flow into their existing systems as seamlessly as possible and produce another layer of valuable intelligence not just drowning them in additional data that data comes from 21 satellites currently in orbit.serafini declined to go into details about the company work there but he said the conflict has highlighted the importance of both commercial remote sensing capabilities in general as well as the need to work closely with the users of those capabilities.paris with a recent funding round and growing demand for its radiofrequency geolocation capabilities hawkeye 360 chief executive says the company has reached an inflection point on the path towards profitability and potentially going public.in a presentation at an investor conference a year ago serafini said the company was considering going public though an initial public offering ipo of stock in two to three years'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con un bucle for rellenamos las columnas de `postexcerprt` que estan vacías con los reumenes generados."
      ],
      "metadata": {
        "id": "BLRSX3f3Wkp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(summaries)):\n",
        "  df['postexcerpt'][i] = summaries[i]"
      ],
      "metadata": {
        "id": "lr-g03xiZi1E"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y podemos comprabar que efectivamente se han rellenado."
      ],
      "metadata": {
        "id": "I-4YIz1fWyb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "atRfFjpTaw2n",
        "outputId": "e2982fa7-3749-4944-c585-0b2b4824b4bc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  HawkEye 360 reaches inflection point on path t...   \n",
              "1     SES Q&A | Leveling up multi-orbit connectivity   \n",
              "2  Rapid Starlink iteration poses challenges for ...   \n",
              "3  Space Force to release guidelines for the use ...   \n",
              "4  ULA has ‘no issues’ with Space Force plan to s...   \n",
              "\n",
              "                                                 url  \\\n",
              "0  https://spacenews.com/hawkeye-360-reaches-infl...   \n",
              "1  https://spacenews.com/ses-qa-leveling-up-multi...   \n",
              "2  https://spacenews.com/rapid-starlink-iteration...   \n",
              "3  https://spacenews.com/space-force-to-release-g...   \n",
              "4  https://spacenews.com/ula-has-no-issues-with-s...   \n",
              "\n",
              "                                             content         author  \\\n",
              "0  paris — with a recent funding round and growin...     Jeff Foust   \n",
              "1  multi-orbit satellite operator ses is on the v...  Jason Rainbow   \n",
              "2  tampa, fla. — spacex’s ability to quickly chan...  Jason Rainbow   \n",
              "3  washington — u.s. chief of space operations ge...   Sandra Erwin   \n",
              "4  washington — united launch alliance, one of ju...   Sandra Erwin   \n",
              "\n",
              "         date                                        postexcerpt  \n",
              "0  2023-09-14  the company longterm goal is to have 60 satell...  \n",
              "1  2023-09-13  after recently deploying the geostationary sat...  \n",
              "2  2023-09-13  we do have channel conflict hofeller said whic...  \n",
              "3  2023-09-13  we will have terms of reference that the space...  \n",
              "4  2023-09-13  washington united launch alliance one of just ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7bc0c294-3bd3-42fc-b576-82dfb37dee6e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>content</th>\n",
              "      <th>author</th>\n",
              "      <th>date</th>\n",
              "      <th>postexcerpt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HawkEye 360 reaches inflection point on path t...</td>\n",
              "      <td>https://spacenews.com/hawkeye-360-reaches-infl...</td>\n",
              "      <td>paris — with a recent funding round and growin...</td>\n",
              "      <td>Jeff Foust</td>\n",
              "      <td>2023-09-14</td>\n",
              "      <td>the company longterm goal is to have 60 satell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SES Q&amp;A | Leveling up multi-orbit connectivity</td>\n",
              "      <td>https://spacenews.com/ses-qa-leveling-up-multi...</td>\n",
              "      <td>multi-orbit satellite operator ses is on the v...</td>\n",
              "      <td>Jason Rainbow</td>\n",
              "      <td>2023-09-13</td>\n",
              "      <td>after recently deploying the geostationary sat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rapid Starlink iteration poses challenges for ...</td>\n",
              "      <td>https://spacenews.com/rapid-starlink-iteration...</td>\n",
              "      <td>tampa, fla. — spacex’s ability to quickly chan...</td>\n",
              "      <td>Jason Rainbow</td>\n",
              "      <td>2023-09-13</td>\n",
              "      <td>we do have channel conflict hofeller said whic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Space Force to release guidelines for the use ...</td>\n",
              "      <td>https://spacenews.com/space-force-to-release-g...</td>\n",
              "      <td>washington — u.s. chief of space operations ge...</td>\n",
              "      <td>Sandra Erwin</td>\n",
              "      <td>2023-09-13</td>\n",
              "      <td>we will have terms of reference that the space...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ULA has ‘no issues’ with Space Force plan to s...</td>\n",
              "      <td>https://spacenews.com/ula-has-no-issues-with-s...</td>\n",
              "      <td>washington — united launch alliance, one of ju...</td>\n",
              "      <td>Sandra Erwin</td>\n",
              "      <td>2023-09-13</td>\n",
              "      <td>washington united launch alliance one of just ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bc0c294-3bd3-42fc-b576-82dfb37dee6e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7bc0c294-3bd3-42fc-b576-82dfb37dee6e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7bc0c294-3bd3-42fc-b576-82dfb37dee6e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-78fcbd9b-dae9-4f45-9828-183703d09a84\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-78fcbd9b-dae9-4f45-9828-183703d09a84')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-78fcbd9b-dae9-4f45-9828-183703d09a84 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1367,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1366,\n        \"samples\": [\n          \"HPE supercomputer in orbit is ready for researchers\",\n          \"SpaceX proceeding with Starship orbital launch attempt after static fire\",\n          \"HawkEye 360 announces $58 million funding round\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1367,\n        \"samples\": [\n          \"https://spacenews.com/hydrosat-acquires-irriwatch/\",\n          \"https://spacenews.com/nasa-suspends-efforts-to-fully-deploy-lucy-solar-array/\",\n          \"https://spacenews.com/space-force-in-wait-and-see-mode-as-ula-continues-to-investigate-upper-stage-anomaly/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1366,\n        \"samples\": [\n          \"san francisco \\u2013 hewlett packard enterprise announced plans nov. 1 to offer researchers and astronauts access to its spaceborne computer, the supercomputer the palo alto, california, company sent to the international space station in august 2017. after a year of testing, hpe has proven its commercial off-the-shelf supercomputer can survive and function reliably in orbit in spite of surprise power outages and fluctuating radiation levels. \\u201cwe have now proven to every scientist and engineer we have that capability,\\u201d mark fernandez, hpe americas high performance computing technology officer, told  spacenews . \\u201cthey can shape their experiments based on the knowledge that a miniature data center is there to help.\\u201d it\\u2019s unlikely astronauts whose schedules are jam-packed will perform calculations on the spaceborne computer anytime soon. researchers, however, may choose to process data in orbit rather than bringing it back to earth, fernandez said. \\u201c bringing supercomputing capabilities on board the international space station will dramatically accelerate data processing and analysis, and in turn, offer new scientific discoveries that drive innovation across various areas,\\u201d dave hornyak, nasa iss technology demonstration research portfolio manager, said in a statement. \\u201cby giving our astronauts and researchers in space high-level performance, the spaceborne computer allows them to convert data into insight more quickly.\\u201d more importantly, hpe has now shown that its supercomputers work in orbit, which means future missions can bring them along. \\u201cif you are headed on a business trip or a vacation, you pack your iphone or ipad with maps, playlists and videos you might need during your journey,\\u201d fernandez said. the spaceborne computer can serve a similar purpose for astronauts traveling to mars or other destinations. \\u201cit\\u2019s unrelated to spacecraft operations,\\u201d fernandez said. \\u201cit can be loaded with the software you need for science, engineering and exploration.\\u201d astronauts heading to mars, for example, will be able to access information without waiting up to 24 minutes for radio signals to travel roundtrip. \\u201cit will enable space explorers and scientists to be self-sufficient,\\u201d fernandez said. when hpe sent the spaceborne computer into orbit, many information technology experts were skeptical, fernandez said at the international space station research and development conference here in july. \\u201cwe took a system from factory floor with no hardening, no preparation, running an open source operating system,\\u201d fernandez said. \\u201cthe majority of the community didn\\u2019t think it would function or wouldn\\u2019t last long.\\u201d hpe relied on software to make the computer resilient. \\u201cwe monitor power, cooling, components,\\u201d fernandez said. \\u201cwhen they get out of nominal range, we isolate them, work around them or do something. each system is self-sufficient with fault detection and isolation.\\u201d similar software could make computers on earth more resilient, fernandez said. hpe is exploring seven patents stemming from the spaceborne computer experiment. fernandez is obviously delighted with the results of the one-year trial because the spaceborne computer overcame numerous challenges, \\u201cthings you cannot plan for or simulate,\\u201d fernandez said. at one point, an iss smoke detector suddenly halted power to the supercomputer. \\u201cpulling the plug on a linux server is about the worst thing you can to it,\\u201d ferdandez said. after diagnostics and health checks, however, the \\u201csoftware did what it was supposed to do\\u201d and computer kept working. on another occasion, an astronaut accidently hit a switch that cutoff power to the spaceborne computer. \\u201cwe\\u2019ve had it all: unscheduled and scheduled power outages caused by equipment failure and human error,\\u201d fernandez said. \\u201cthey are completing my experiment.\\u201d nasa officials were surprised how well the spaceborne computer worked.  \\u201cthe spaceborne computer itself had no difficulties from the time it was powered on through the entire one year run,\\u201d hornyak said. \\u201ctypically with any new system, there are commissioning and setup adjustments needed, but that wasn\\u2019t required with the spaceborne computer. it powered on at the start, and ran reliably the entire test duration.\\u201d the 56-kilogram spaceborne computer fits in an iss ceiling mounted server rack that is about 30 centimeters by 61 centimeters by 91 centimeters.\",\n          \"orlando \\u2014 spacex\\u2019s static-fire test of nearly all the engines in its starship booster earlier this month was \\u201cthe last box to check\\u201d before the vehicle\\u2019s first orbital launch attempt, likely some time in march, a company official said feb. 21. speaking on a panel at the space mobility conference here about \\u201crocket cargo\\u201d delivery, gary henry, senior advisor for national security space solutions at spacex, said both the super heavy booster and its launch pad were in good shape  after the feb. 9 test , clearing the way for an orbital launch that is still pending a federal aviation administration launch license. \\u201cwe had a successful hot fire, and that was really the last box to check,\\u201d he said. \\u201cthe vehicle is in good shape. the pad is in good shape.\\u201d only 31 of the 33 raptor engines in the super heavy booster fired. spacex chief executive elon musk tweeted just after the test that one engine was commanded off just before ignition and a second shut down early. he later said that the engines ran at 50% of their rated thrust. that led to speculation that spacex would need to perform a second static-fire test to get all 33 engines, or to run them at higher thrust levels. henry, though, suggested that spacex was not planning another such test before an orbital launch attempt. \\u201cpretty much all of the prerequisites to supporting an orbital demonstration attempt here in the next month or so look good,\\u201d he said. the company still needs to obtain an faa launch license before attempting the launch. \\u201cwe hope to secure that license in the very near future,\\u201d he said, setting up a launch attempt \\u201cprobably in the month of march.\\u201d once spacex performs that orbital launch demonstration, henry said the company is ready to move ahead rapidly with operational starship launches. \\u201cwe very, very quickly converge on a system that we can operationalize,\\u201d he said, starting with launches of second-generation starlink satellites. \\u201cwe have a few that are waiting very patiently to be launched on starship.\\u201d those initial starlink launches will serve as a test program, he explained, refining the launch and recovery of the two stages of starship. \\u201csomewhere in that journey that will be happening this year, we\\u2019re going to make a major pivot to the next piece of the human landing system architecture,\\u201d he said, by demonstrating the orbital depot needed for on-orbit refueling of the lunar lander version of starship. that will provide additional experience testing starship through the tankers that will fly to deliver propellant to the depot. \\u201cthe nice thing about tankers is that they\\u2019ve got to reenter as well,\\u201d he said. \\u201cwe\\u2019ve created this rubric, in the next year or two, where we will be able to do a lot of experimentation on that thermal protection system that will allow successful reentry of starship.\\u201d starship, henry argued later in the panel, will sharply drive down launch costs. \\u201cwe are on the cusp of seeing an opportunity of mass to orbit go from $2,000 a kilogram to $200 a kilogram,\\u201d he said. in the long term, costs could further decline to the point where the propellant is the largest factor in the per-launch marginal cost. \\u201cif elon gets his way,\\u201d he said, \\u201cyou\\u2019re at $20 per kilogram.\\u201d\",\n          \"washington \\u2014  hawkeye 360, a  commercial operator  of remote-sensing satellites, announced july 13 it has raised $58 million in new funding.  based in herndon, virginia, the company uses radio-frequency data collected by satellites to geolocate electronic emissions and draw insights.  \\u201cthe funding will be used to develop new space systems and expand analytics that support high-value defense missions,\\u201d hawkeye 360 ceo john serafini said in a news release. the series d-1 round was led by funds and accounts managed by blackrock with additional funding provided by manhattan venture partners and existing investors including insight partners, nightdragon, strategic development fund, razor\\u2019s edge, alumni ventures and adage capital. \\u201cwe\\u2019ll use this funding to drive our next steps in innovation,\\u201d serafini said. \\u201cit speaks volumes that these leading investment firms are confident in the future of rf geospatial intelligence as a critical defense technology.\\u201d new \\u2018block 3\\u2019 satellites planned the company, founded in 2015, operates a constellation of 21 satellites that detect, characterize and geolocate radio frequency signals from emitters used for communication, navigation and security. the satellites fly in triangular \\u201cclusters\\u201d in low earth orbit.  the new funding will help accelerate the transition to a new block 3 satellite architecture starting with cluster 14, the company said. it also plans to increase investments in artificial intelligence, data fusion and multi-intelligence orchestration to better extract value from the large amount of rf data being collected.  \\u201cgovernments and commercial customers are asking for better intelligence and, with its full chain of control from orbit to analytics, hawkeye 360 is leading the way for this new category of rf space-based data,\\u201d said matt singer, managing director of blackrock.  \\u201chawkeye 360 has disrupted what used to be a static defense intelligence domain,\\u201d said jared carmel, managing partner and general partner of manhattan venture partners. \\u201c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 41,\n        \"samples\": [\n          \"Jeff Foust for The Space Review\",\n          \"Andrew Parsonson\",\n          \"Miriam Klaczynska\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2009-02-11\",\n        \"max\": \"2023-09-14\",\n        \"num_unique_values\": 374,\n        \"samples\": [\n          \"2016-04-13\",\n          \"2023-08-09\",\n          \"2023-08-28\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"postexcerpt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1346,\n        \"samples\": [\n          \"we have now completed our enhancements and i am incredibly appreciative of our team for the long hours that they put in to return these ships to flight vss unity remained at spaceport america during the overhaul of vms eve and the company says both vehicles are now ready for a series of test flights from the spaceport which will include both a glide flight and a powered test flight of vss unity the latter with virgin galactic personnel on board.in a feb 28 earnings call to discuss the company 2022 fourth quarter and full year financial results virgin galactic chief executive michael colglazier said commercial flights of its spaceshiptwo vehicle vss unity are slated to begin in the second quarter a schedule the company has kept in recent months after previous extensive delays.the company had negative free cash flow of 135 million in the fourth quarter of 2022 and projected similar negative free cash flow for the first quarter of 2023 doug ahrens chief financial officer said on the call that virgin galactic has pretty significant ability to adjust spending if needed to reduce those losses.we are going to make sure we have both of those aforementioned scopes of work dialed in and well in hand he said of returning to flight and nextgeneration vehicle work and when that happens we will come pick up imagine and see where we want to go virgin galactic reported revenue of 23 million for 2022 with a net loss of 500 million.colglazier said that this year is now focused on completing designs for both the next generation motherships and delta spaceships building the required tooling and beginning the parts fabrication for the ships those vehicles are slated to enter commercial service in 2026 left in limbo though is vss imagine the company next suborbital spaceplane.the company said in november that it was slowing work on the vehicle to focus on getting vms eve and vss unity back to flight while starting development of its nextgeneration vehicles\",\n          \"companies have all seen an infusion of cash through the requirements generated by what is going on in europe and increased concern with respect to taiwan regardless of how the ukraine crisis is ultimately resolved this has changed the nature of the application of space based technologies forever said masback.masback told spacenews he expects cognitive space to grow its business as both commercial and government satellite operators need better tools to manage their constellations more efficiently.guy de carufel founder and ceo of cognitive space said masback has been an advisor to the company for the past two years\",\n          \"the academy of aerospace solid propulsion technology aaspt under the china aerospace science and technology corporation casc recently carried out a launch test in the gobi desert in northwest china casc announced june 23 the test payload also carried a sample return device developed by the beijing institute of space machinery and electronics bisme under the china academy of space technology cast another major casc subsidiary.the tests are for the tianwen2 asteroid sample return and comet rendezvous mission which is currently scheduled to lift off on a long march 3b rocket in may 2025 the mission will target the nearearth asteroid 469219 kamo\\u02bboalewa collecting samples and returning to earth around 25 years after launch.the service module for that mission used the return to earth as flyby to embark on an extended mission to sunearth lagrange point 1 casc noted the construction of the tianwen2 spacecraft as a key goal in its 2023 plans along with building the change7 lunar south pole landing mission spacecraft.helsinki china main space contractor has conducted several successful highaltitude parachute deployment tests as part of plans to collect asteroid samples and deliver them safely to earth.casc has developed parachutes for reenteries for its human spaceflight program the tianwen1 mars rover landing and for the 2020 change5 and upcoming change6 lunar sample return missions\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último guardamos el DataSet con el formato .rda para su posterior anális en R."
      ],
      "metadata": {
        "id": "nK4mMjKuW3D_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el DataFrame en un archivo .rda\n",
        "pyreadr.write_rdata(\"datos_space_resumen.rda\", df)"
      ],
      "metadata": {
        "id": "YgGwMYnkbHN9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODELOS PREENTRENADOS"
      ],
      "metadata": {
        "id": "-5lnoA77F-F0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install bert-extractive-summarizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf2S63qBGBDV",
        "outputId": "92717111-b2d4-4f89-dfe5-1f5dd7eee530"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: bert-extractive-summarizer in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from bert-extractive-summarizer) (4.40.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from bert-extractive-summarizer) (1.2.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from bert-extractive-summarizer) (3.7.4)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (0.4.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers->bert-extractive-summarizer) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers->bert-extractive-summarizer) (4.11.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->bert-extractive-summarizer) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->bert-extractive-summarizer) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->bert-extractive-summarizer) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->bert-extractive-summarizer) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->bert-extractive-summarizer) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy->bert-extractive-summarizer) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy->bert-extractive-summarizer) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->bert-extractive-summarizer) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->bert-extractive-summarizer) (1.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Librerias"
      ],
      "metadata": {
        "id": "8ZkJIenjGJ_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import transformers\n",
        "from summarizer import Summarizer, TransformerSummarizer"
      ],
      "metadata": {
        "id": "ml9J7Dt5GQK5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelos"
      ],
      "metadata": {
        "id": "59RcpY_fGVUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(model, text):\n",
        "    summary = ''.join(model(text, min_length=50))\n",
        "    print(f'Summmery by {model}:\\n\\n\\n{summary} \\n\\n\\n')\n",
        "    print(f'---------------------------------------------------*---------------------------------------------------')"
      ],
      "metadata": {
        "id": "lSL_nut7GWcP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probamos a realizar un resumen con la primera noticia."
      ],
      "metadata": {
        "id": "6HxIZdJzGcnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text='''\n",
        "PARIS — With a recent funding round and growing demand for its radio-frequency geolocation capabilities, HawkEye 360’s chief executive says the company has reached an “inflection point” on the path towards profitability and potentially going public.\n",
        "\n",
        "HawkEye 360 announced July 13 it raised $58 million in a Series D-1 round led by BlackRock. The company said then that the funding would support development of new satellites and analytics products.\n",
        "\n",
        "The company has raised $368 million to date, said John Serafini, chief executive of HawkEye 360, in an interview during World Satellite Business Week here Sept. 13. That round may also be the last private funding the company needs to raise.\n",
        "\n",
        "“Provided that we execute against our revenue forecasts, which are conservative and we think we can do, we won’t need to raise additional private capital,” he said. Profitability, he added, “is on the horizon for us,” but didn’t offer a specific timeline for achieving it.\n",
        "\n",
        "In a presentation at an investor conference a year ago, Serafini said the company was considering going public though an initial public offering (IPO) of stock in two to three years. That is still the plan now, he said, although the timing will depend as much on market conditions as it will the state of the company.\n",
        "\n",
        "“The market being open or closed has a lot to do with it,” he said of the timing of an IPO, which he said remains likely two to three years out. “Whether we can achieve the requisite milestones is the biggest issue,” such as achieving profitability and the right unit economics. “That’s what we can control and we’re rushing like heck to get to that spot.”\n",
        "\n",
        "The new funding and the growth of the business have put HawkEye 360 into a good position, he argued. “I would say we’re at an inflection point,” he said, from the funding to plans to launch additional satellites and development of analytics tools that leverage machine learning and artificial intelligence. “All of that in the next 12 to 18 months has got us in a great position.”\n",
        "\n",
        "Governments remain the largest customers for HawkEye 360, which Serafini said will likely be the case for the foreseeable future. That has included defense and intelligence applications as well as some civil and broader security applications, like tracking illegal fishing or deforestation.\n",
        "\n",
        "“One of the tenets we set the company up with was to focus on where the money is. The money in remote sensing is, ultimately, in defense and intelligence,” he said. “If you can’t service those customers, you’re not going to exist as a company.”\n",
        "\n",
        "That work has included work in Ukraine since Russia’s invasion more than a year and a half ago, tracking sources of GPS and other radio-frequency interference. Serafini declined to go into details about the company’s work there, but he said the conflict has highlighted the importance of both commercial remote sensing capabilities in general as well as the need to work closely with the users of those capabilities.\n",
        "\n",
        "“Throwing remote sensing data over a fence probably doesn’t lead to success,” he said. “One of the areas of growth for HawkEye is understanding the tactical intelligence, surveillance, reconnaissance requirements of our customers, and the networks and systems that they operate in, such that our data can flow into their existing systems as seamlessly as possible and produce another layer of valuable intelligence, not just drowning them in additional data.”\n",
        "\n",
        "That data comes from 21 satellites currently in orbit. Six more are scheduled to launch later this year on a Rocket Lab Electron from New Zealand. The company’s long-term goal is to have 60 satellites, in 20 three-satellite clusters, which Serafini said the company expects to achieve by 2025 or 2026.\n",
        "\n",
        "Those satellites, built both by the Space Flight Laboratory at the University of Toronto Institute for Aerospace Studies as well as HawkEye 360’s own facility in Northern Virginia, will be a mix of both its existing Block 2 design and new Block 3 design. The plans for Block 3 are “very fluid,” he said, and could feature two different designs, a smaller one to focus on specific signals and a larger one to do “very advanced” work.\n",
        "\n",
        "HawkEye 360 also announced Sept. 12 it promoted Rob Rainhart, the company’s chief operating officer since 2019, to president.\n",
        "\n",
        "“Rob and I have been partners together for eight years,” Serafini said. Rainhart handles internal company operations, responsibilities he will continue as president. “He keeps the company running on time, and so it felt like the right time to make the move to promote him to president.”\n",
        "'''"
      ],
      "metadata": {
        "id": "8Wy8e75yGhQX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resumen con tres modelos preentrenados"
      ],
      "metadata": {
        "id": "AfeflpSjGm5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_bert = Summarizer() #Defining bert model\n",
        "\n",
        "#Defining gpt2 model\n",
        "model_gpt2 = TransformerSummarizer(transformer_type = \"GPT2\", transformer_model_key=\"gpt2-medium\")\n",
        "\n",
        "#Defining xlnet model\n",
        "model_xlnet = TransformerSummarizer(transformer_type = \"XLNet\", transformer_model_key = \"xlnet-base-cased\")"
      ],
      "metadata": {
        "id": "ryM7TpgTGk9x"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(model_bert, text)\n",
        "summarize(model_gpt2, text)\n",
        "summarize(model_xlnet, text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsewEXyeHTGd",
        "outputId": "0108fffa-8349-4835-f565-2c3b9af65c95"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summmery by <summarizer.bert.Summarizer object at 0x7d45a55ccb20>:\n",
            "\n",
            "\n",
            "PARIS — With a recent funding round and growing demand for its radio-frequency geolocation capabilities, HawkEye 360’s chief executive says the company has reached an “inflection point” on the path towards profitability and potentially going public. The company has raised $368 million to date, said John Serafini, chief executive of HawkEye 360, in an interview during World Satellite Business Week here Sept. 13. In a presentation at an investor conference a year ago, Serafini said the company was considering going public though an initial public offering (IPO) of stock in two to three years. That has included defense and intelligence applications as well as some civil and broader security applications, like tracking illegal fishing or deforestation. “Throwing remote sensing data over a fence probably doesn’t lead to success,” he said. “ That data comes from 21 satellites currently in orbit. Six more are scheduled to launch later this year on a Rocket Lab Electron from New Zealand. \n",
            "\n",
            "\n",
            "\n",
            "---------------------------------------------------*---------------------------------------------------\n",
            "Summmery by <summarizer.bert.TransformerSummarizer object at 0x7d45a55cc9d0>:\n",
            "\n",
            "\n",
            "PARIS — With a recent funding round and growing demand for its radio-frequency geolocation capabilities, HawkEye 360’s chief executive says the company has reached an “inflection point” on the path towards profitability and potentially going public. The company has raised $368 million to date, said John Serafini, chief executive of HawkEye 360, in an interview during World Satellite Business Week here Sept. 13. Profitability, he added, “is on the horizon for us,” but didn’t offer a specific timeline for achieving it. I would say we’re at an inflection point,” he said, from the funding to plans to launch additional satellites and development of analytics tools that leverage machine learning and artificial intelligence. “ That has included defense and intelligence applications as well as some civil and broader security applications, like tracking illegal fishing or deforestation. That data comes from 21 satellites currently in orbit. He keeps the company running on time, and so it felt like the right time to make the move to promote him to president.” \n",
            "\n",
            "\n",
            "\n",
            "---------------------------------------------------*---------------------------------------------------\n",
            "Summmery by <summarizer.bert.TransformerSummarizer object at 0x7d45a57a0be0>:\n",
            "\n",
            "\n",
            "PARIS — With a recent funding round and growing demand for its radio-frequency geolocation capabilities, HawkEye 360’s chief executive says the company has reached an “inflection point” on the path towards profitability and potentially going public. I would say we’re at an inflection point,” he said, from the funding to plans to launch additional satellites and development of analytics tools that leverage machine learning and artificial intelligence. “ All of that in the next 12 to 18 months has got us in a great position.” Governments remain the largest customers for HawkEye 360, which Serafini said will likely be the case for the foreseeable future. “One of the tenets we set the company up with was to focus on where the money is. That data comes from 21 satellites currently in orbit. HawkEye 360 also announced Sept. 12 it promoted Rob Rainhart, the company’s chief operating officer since 2019, to president. \n",
            "\n",
            "\n",
            "\n",
            "---------------------------------------------------*---------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EXTRA**"
      ],
      "metadata": {
        "id": "Ph-lic_iG77z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "También nos parecio interesante intentar generar nuestro propio articulo con ayuda de Deep Learning y NLP, creando y entrenando nuestro propio modelo. Para ello nos ayudamos del siguiente Notebook:\n",
        "\n",
        "- https://www.kaggle.com/code/asif00/text-generation-with-tensorflow-nlp-rnn"
      ],
      "metadata": {
        "id": "wd2FrJf6G_fp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Librerias"
      ],
      "metadata": {
        "id": "SFhDchBoHdJO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta parte se han quitado algunas librerias ya que estaban importadas previamente en la parte donde generamos los resúmenes."
      ],
      "metadata": {
        "id": "nI36F1ppH8Rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pyreadr\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "tt7g94N3HbBw"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "metadata": {
        "id": "xy2BKlALHKFS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La parte de crear un dataset importando el DataSet de R es igual que en la primera parte de los resúmenes. Lo único nuevo es que aqui solo nos interesa la parte de contenido de la noticia."
      ],
      "metadata": {
        "id": "3B3K14WCIEwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['content']]"
      ],
      "metadata": {
        "id": "MjadzMeXPGzi"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos un corpus que al igual que hemos mencionado anteriormente, aunque se haya hecho en R aquí no tenemos el corpus."
      ],
      "metadata": {
        "id": "1He3XGtHQX_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = []\n",
        "with strategy.scope():\n",
        "    for key, value in df.items():  # Iterar sobre los elementos (clave, valor) del diccionario\n",
        "        if isinstance(value, pd.Series):  # Verificar si el valor es un Series de Pandas\n",
        "            lowercase_values = value.str.lower()  # Convertir todo el valor a minúsculas\n",
        "            corpus.extend(lowercase_values)  # Extender la lista con los valores procesados\n",
        "        elif isinstance(value, pd.DataFrame):  # Verificar si el valor es un DataFrame de Pandas\n",
        "            lowercase_values = value.applymap(lambda x: x.lower() if isinstance(x, str) else x)  # Convertir todo el DataFrame a minúsculas\n",
        "            corpus.append(lowercase_values)  # Agregar el DataFrame procesado a la lista\n",
        "        else:\n",
        "            corpus.append(value)  # Agregar otros tipos de datos directamente\n",
        "\n",
        "corpus[:10]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0ar0LxCIPZY",
        "outputId": "8fc8a6e9-adff-433c-edfd-5d00f549a55a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['paris — with a recent funding round and growing demand for its radio-frequency geolocation capabilities, hawkeye 360’s chief executive says the company has reached an “inflection point” on the path towards profitability and potentially going public. hawkeye 360 announced july 13  it raised $58 million in a series d-1 round  led by blackrock. the company said then that the funding would support development of new satellites and analytics products. the company has raised $368 million to date, said john serafini, chief executive of hawkeye 360, in an interview during world satellite business week here sept. 13. that round may also be the last private funding the company needs to raise. “provided that we execute against our revenue forecasts, which are conservative and we think we can do, we won’t need to raise additional private capital,” he said. profitability, he added, “is on the horizon for us,” but didn’t offer a specific timeline for achieving it. in a presentation at an investor conference a year ago,  serafini said the company was considering going public  though an initial public offering (ipo) of stock in two to three years. that is still the plan now, he said, although the timing will depend as much on market conditions as it will the state of the company. “the market being open or closed has a lot to do with it,” he said of the timing of an ipo, which he said remains likely two to three years out. “whether we can achieve the requisite milestones is the biggest issue,” such as achieving profitability and the right unit economics. “that’s what we can control and we’re rushing like heck to get to that spot.” the new funding and the growth of the business have put hawkeye 360 into a good position, he argued. “i would say we’re at an inflection point,” he said, from the funding to plans to launch additional satellites and development of analytics tools that leverage machine learning and artificial intelligence. “all of that in the next 12 to 18 months has got us in a great position.” governments remain the largest customers for hawkeye 360, which serafini said will likely be the case for the foreseeable future. that has included defense and intelligence applications as well as some civil and broader security applications, like tracking illegal fishing or deforestation. “one of the tenets we set the company up with was to focus on where the money is. the money in remote sensing is, ultimately, in defense and intelligence,” he said. “if you can’t service those customers, you’re not going to exist as a company.” that work has included work in ukraine since russia’s invasion more than a year and a half ago,  tracking sources of gps and other radio-frequency interference . serafini declined to go into details about the company’s work there, but he said the conflict has highlighted the importance of both commercial remote sensing capabilities in general as well as the need to work closely with the users of those capabilities. “throwing remote sensing data over a fence probably doesn’t lead to success,” he said. “one of the areas of growth for hawkeye is understanding the tactical intelligence, surveillance, reconnaissance requirements of our customers, and the networks and systems that they operate in, such that our data can flow into their existing systems as seamlessly as possible and produce another layer of valuable intelligence, not just drowning them in additional data.” that data comes from 21 satellites currently in orbit. six more are scheduled to launch later this year on a rocket lab electron from new zealand. the company’s long-term goal is to have 60 satellites, in 20 three-satellite clusters, which serafini said the company expects to achieve by 2025 or 2026. those satellites, built both by the space flight laboratory at the university of toronto institute for aerospace studies as well as hawkeye 360’s own facility in northern virginia, will be a mix of both its existing block 2 design and new block 3 design. the plans for block 3 are “very fluid,” he said, and could feature two different designs, a smaller one to focus on specific signals and a larger one to do “very advanced” work. hawkeye 360 also announced sept. 12 it promoted rob rainhart, the company’s chief operating officer since 2019, to president. “rob and i have been partners together for eight years,” serafini said. rainhart handles internal company operations, responsibilities he will continue as president. “he keeps the company running on time, and so it felt like the right time to make the move to promote him to president.”',\n",
              " 'multi-orbit satellite operator ses is on the verge of realizing key strategic goals that have been years in the making.  after recently deploying the geostationary satellites  needed to claim around $3 billion  in c-band spectrum clearing proceeds, the company is now just months away from launching initial services for its upgraded o3b mpower broadband network in medium earth orbit (meo). so many were surprised to see  steve collar’s june 12 announcement  that he was retiring as ceo two weeks later, following more than 20 years with the luxembourg-based operator, including five years at the helm. collar was replaced by ruy pinto, who joined the company in 2017 and was previously its chief technology officer. in his first ses earnings call as ceo aug. 3, pinto  said an electrical glitch  on the first four o3b mpower satellites was sporadically tripping off power modules — although the trip-offs could be resolved quickly without affecting payload performance.  still, the issue has delayed the launch of the fifth and sixth o3b mpower satellites, which are needed for initial services and were slated to launch by the end of june as of the operator’s previous earnings call. boeing is contracted to provide 11 ka-band o3b mpower satellites to enable full services from the operator’s second-generation meo constellation. spacenews  caught up with pinto on the sidelines of euroconsult’s world satellite business week conference in paris to learn more about how the operator is tackling its opportunities and challenges. steve collar’s sudden departure as ceo in june surprised many in the industry. was it also a surprise for you? it was a surprise to a certain extent. but steve is staying on as an advisor and is very much engaged in what is happening with the industry and what is happening with ses — i talk to him quite often. was it partly a result of diverging views with the board? the board, steve, the management team, and myself have been very consistent on our strategy. we have strong financials, we’ve focused on our unique capabilities around meo, we are investing in o3b mpower, and we believe in our strong position in markets like cruise and government. we have also been looking at consolidation in the industry. we have acquired  [satcoms provider] drs  and we’ve doubled down on our u.s. government business — a great acquisition and we’re really pleased with that.  we did look at other options, as we should. we tried to reach a good deal with intelsat over quite some period of time that didn’t work.  but we do believe in the logic of consolidation in the industry. we are on the record saying consolidation is a good thing in a disrupted industry like ours.  so it wasn’t connected with what happened with intelsat, or what didn’t happen? there wasn’t a single thing, and certainly not the negotiations with intelsat. the negotiations were difficult, otherwise intelsat and ses would have reached an agreement. in steve’s words, there is a shelf life to all ceos, and it was time for him to go, especially since he felt he was leaving ses in good hands.  how could the company’s strategy change under your leadership? there is no fundamental shift in the strategy i just outlined, but strategy is not fixed in time, as well. you can think of strategy as a budget. the moment you finalize a budget, the market and customers move on, and the budget has to be updated. the main tenets of our strategy are:  with the receipt of the c-band proceeds, which should happen this year, our balance sheet will have a good position in the industry, being an investment-grade company with good cash flows and money to invest in opportunities that are sensible. not throwing money out of the window, but being selective and objective on where we can invest in technology, partnerships, and products to leverage our strong financial position.  and of course, there’s competition from starlink, and future competition from project kuiper and telesat lightspeed. we also all expect  the deal between eutelsat and oneweb will close soon , so that will be another data point. and there’s also potential competition coming to meo, such as intelsat as it  explores options for this orbit . i’m very proud that intelsat has followed our strategy in meo. they’re endorsing what we have been thinking for quite some time — 10 years. but on a more serious side, firstly, they’re in a different frequency. intelsat have a lot of assets in ku-band.  and even if they were to give you a press release tomorrow with a firm commitment, it will take some time for them to get into orbit to learn what we have learned over the years, and get the experience in software, hardware, infrastructure, and ground segment.  i’m mindful, but i’m not losing any sleep over that. do you expect to decide soon on how to invest the c-band proceeds? rushing doesn’t necessarily help. we have to be quick once we make a decision, but we don’t necessarily need to be quick in reaching that decision on how best to deploy the capital that we will have.  a big source of current investment is o3b mpower. where are you in resolving the technical glitch you recently disclosed there? we have been working really hard with boeing and we have a way better understanding of this phenomena than we had two months ago. this gives us the confidence that we can provide the level of service that our customers expect, and that we expect from o3b mpower.  with a mix of operational [changes and] updates to the software, we can live with this phenomenon. it doesn’t impact the lifetime of those satellites as far as we know. the current plan is that we are on target to launch the next two in october. we did some small things on them that we hope to mitigate this phenomenon, but it’s not something that prevents us from getting o3b mpower working.  and that’s really good news. we are going to put in place a constellation with about 10 years of expected lifetime, so for the sake of one, two, or three months, it doesn’t detract us from doing the right thing.  you have seen  the unfortunate experiences that viasat has had  over the last two months as a sign that sometimes being a little bit more conservative, and really understanding how the technology performs in a harsh environment, pays off. what changes did you make to the two upcoming satellites? they are good things to do in terms of shielding and cabling. we don’t expect them to be a silver bullet for the phenomena we have observed, but they’re sensible things to do. of course, launching them gives boeing and us time to go from: now we understand what is happening to can i just prevent it from happening altogether on the following five satellites? are they packed up and ready for the launchpad? they’re not packed up yet, but if we’re going to meet a launch in october we’re going to have to ship them by the end of september. what is your take on the potential for price erosion from the masses of satellites launching in the coming years? when you have a competitor like starlink, which is increasing its capacity at a fast pace, the demand will continue being outstripped by the supply in certain geographies and markets, and that will drive price erosion. it’s just the nature of competition. but there will be other geographies and market segments. for the concentration of cruise ships in the mediterranean in the summer, the supply doesn’t meet the demand there. so we should be able to have profitable pricing in that geography and at that time, for example, and there are also hotspots in government and aviation. o3b mpower’s ability to shift capacity from a to b, based on need and time of day, allows us to provide a capability and flexibility that our customers will be willing to pay a premium for. it was interesting to see ses  partner with starlink  in the cruise market, which has been a stronghold for you. how did that deal come about? we were the first to launch on a reusable falcon 9, and we have discussed possible joint initiatives in the past. our customers in the cruise market have been saying, look, the market is evolving and there is a lot of demand for connectivity. we would like to have the starlink capability available for our ships — it’s not guaranteed, it may not have burst capacity or the flexibility that you have on meo, but we want it for certain applications. at the same time, we also want meo. given customers want the best of both worlds, and have been coming to us saying we want the capability that starlink brings, we decided to partner with starlink to sell this managed service to the market. we’re still giving our customers a choice. nobody is forcing them to go left or right, but going jointly to certain customers who want it is way better for both companies. and it’s a model that we may wish to discuss or replicate in very selective opportunities, markets or geographies. it doesn’t mean starlink will not compete directly with us in certain adjacent markets, and vice versa. we’ve seen intelsat and inmarsat  buy small satellites for their geostationary businesses  recently. are smaller, more regionally focused satellites in geostationary orbit (geo) also of interest to ses? we don’t have any short-term plans for geo replacements. we have time. but for our next neighbor slot where we need to replace our geo capacity, we are going to look at those options.  there is potential. if they can prove their viability, the price points, and the scale and flexibility, then of course we’re going to look at it. you have partnered with eutelsat to bid for a role in iris². are you concerned that their acquisition of u.k.-based oneweb could complicate what is a very european project? if that turns out to be an issue, it’s more of a eutelsat concern than ours. having said that, we are part of a team and we believe we have put together something that’s potentially very compelling for the european commission. this interview has been edited for length and clarity',\n",
              " 'tampa, fla. — spacex’s ability to quickly change and update services has been awkward for resellers, an executive for the low earth orbit (leo) broadband constellation said sep. 13. “it’s been challenging because we are so nimble,” starlink vice president of commercial sales jonathan hofeller said sept. 13, “and we have to be smarter about how [this] affects our resellers.” he said it’s not uncommon for spacex to want to add a starlink plan on a friday and then adopt it monday. “well, that affects our partners and we’re learning how to be better partners in that sense,” he said on a panel for world satellite business week in paris. however, he said starlink’s ability to iterate rapidly helps the company adapt to changing customer needs and plans.  the constant refining also enables starlink react to sudden events, such as natural disasters and other changes on a regional or global basis. spacex can also change and update starlink services at pace because the vertically integrated company builds and launches the satellites in-house.  after initially solely focusing on selling directly to consumers, starlink opened up to reseller channels about a year ago to help expand into markets including maritime, energy, and aviation. “we do have channel conflict,” hofeller said, “which is one of the things that we’re exploring and … figuring out how to work through.” but starlink is “also seeing that customers look for additional added services such as cybersecurity, install, customer support — above and beyond just great, raw, high-speed, low-latency capacity,” and so the company is “looking to our partners to provide that to the end customers.” starlink announced a partnership earlier in the day with ses, which operates a constellation of geostationary and medium earth orbit satellites, to provide a combined service for cruise lines. ses is taking the lead on selling and managing the joint offering, including antenna installation. the financials starlink now has more than 1.5 million customers worldwide, according to hofeller. while he did not discuss financials, he said the company is no longer subsidizing user antennas. starlink achieved $1.4 billion in revenues for 2022 compared with $222 million the year before,  reported the wall street journal sept. 13 , citing documents. according to the report, the company projected in a 2015 investor presentation that starlink would net nearly $12 billion in revenue for 2022 and have 20 million subscribers by the end of that year, as well as $7 billion in operating profit. last month, t he wall street journal reported  that spacex had made a $55 million profit for the first three months of 2023, following a loss for 2022. spacex has not commented on these reports. hofeller was asked during the conference about the failure rate for the more than 5,000 starlink satellites launched to date — tracked by third party  spaceflight observer jonathan mcdowell  — and he said he did not know this data. massimiliano ladovaz, oneweb’s chief technology officer, told conference delegates it had four failures after deploying more than 630 satellites for its constellation.  “obviously we would have loved not to have those four failures,” he said, but “considering that it’s newspace, it’s quite a low percentage.”',\n",
              " 'washington — u.s. chief of space operations gen. chance saltzman said the space force is finalizing a blueprint for how it will integrate commercial satellite services into military activities.  “one way we are enhancing our relationships with commercial partners is through a soon to be released commercial space strategy,” saltzman said sept. 13 at the global aerospace summit organized by the u.s. chamber of commerce.  “this new strategy will provide a unifying guidance to the force to achieve competitive advantage through commercial augmentation,” he said. the space force and the u.s. military at large rely on commercial companies for a wide range of peacetime and wartime services, but saltzman said there is need for specific guidance on emerging space industry services — such as rapid-revisit satellite imaging and low-earth orbit satellite communications — many of which have only become available in recent years. he characterized the current period as a “true golden era for commercial space.” “one way we are addressing future challenges is by exploring ways to better integrate commercial space,” saltzman said.  “commercial capabilities, services and activities are expanding rapidly. the competition we are seeing today in commercial space is driving innovation and the space force wants to harness these efforts,” he said. “we know our commercial partners are a big reason that we can out compete our adversaries.” “the speed and innovation offered by the commercial space sector can create a strategic advantage,” saltzman said. the goal of the strategy is to help harness that innovation, he added. “i’m hopeful it will be approved and published in the weeks to come.” ‘terms of reference’ saltzman said the new guidance will help clarify the role of commercial providers and how their capabilities might be integrated into military operations, he added. “we will have terms of reference that the space force has created to help our industry partners address the augmentation and integration of commercial space capabilities.” “my hope is that this will bring some clarity to the industry so that they can globally support and augment inherently governmental and military activities that we project from the space domain,” saltzman explained. “ as the conflict in ukraine has shown us , space is critical to modern warfare,” he said. “it has played a vital role in communications, precision navigation and timing, missile warning, command and control, intelligence surveillance and reconnaissance.” “commercial augmentation has proven its value during this conflict,” particularly in satellite-based surveillance. “it’s unclassified. it has promoted shareability it has enabled us to supplement classified data, he added. ‘fundamental conversation’ the commercial strategy is intended to help space force buyers and contractors speak the same language, saltzman said. “it’s important that we’re all having the same fundamental conversation. we have to define our terms.” for example, he said, “we define augmentation as the use of commercial space goods, services and activities to increase both capacity and resilience. similarly, we define what we mean by commercial activity, what is a critical function, what are inherently governmental functions, what tasks can be executed by the private sector.”  with regard to the protection of satellites during conflicts, saltzman noted that the space force intends to work with military allies and private companies to ensure collective security, enabled by data sharing. “going forward, all space users will be in the combat zone during a conflict. you cannot separate civilian and military assets in this domain. so we all share the risk if a war comes to space.” “we need to increase our collaboration with the commercial space industry to enable new capabilities that support integrated deterrence,” he said. this integration includes data sharing, and interoperability between our allies and industry partners.”',\n",
              " 'washington — united launch alliance, one of just two u.s. companies that provide national security launch services, does not have a problem with dod’s decision to add a third competitor, a senior ula executive said sept. 13. gary wentz, ula’s vice president of government and commercial programs, said the company is supportive of the u.s. space force’s proposed strategy to add a third heavy-lift launch provider in the next round of contracts, known as  national security space launch phase 3.  “from what we saw relative to lane 2 and the addition of a third provider, we didn’t see any issues with that,” wentz said during a panel discussion at the global aerospace summit organized by the u.s. chamber of commerce. currently ula and spacex are the only nssl launch providers. due to concerns about growing commercial demand, the space force said it plans to select a third provider in lane 2 of nssl phase 3, creating an opportunity for a new entrant like blue origin which is developing a heavy rocket.  lane 2 providers have to be able to fly to low, medium and high orbits. of the  58 missions expected to be procured under lane 2, seven — five gps satellite launches to medium earth orbit and two direct-to-geostationary orbit launches — will be set aside for a third provider, space force officials said. ula’s ceo tory  bruno in july expressed concerns  about the phase 3 strategy and said he was still reviewing the details. one of bruno’s concerns was that “it’s not a competition if everybody wins.” a ula spokesperson in a statement sept. 13 noted that bruno in an interview last month with  aviation week  said :  “we understand the government’s need to have a broader industrial base at this time of challenge … so we’re ok with the third provider,”  the spokesperson said bruno had concerns about other points in the draft request for proposals not related to a third provider. wentz said the company reviewed the latest draft solicitation and is on board with the plan to add a third provider. he noted that there are now more missions in lane 2 than had been previously forecast so allocating seven to a third provider seems reasonable. “so we support it,” he said.  blue origin ‘looking at the rfp’ blue origin’s vice president of government sales lars hoffman — also speaking at the chamber of commerce event — said the company continues to work with the space force to develop a plan to certify the new glenn rocket for nssl after it starts flying — which the company projects will happen in 2024. “we’ve been doing that for a while,” said hoffman. “so we’re actively engaged with them on that front. things are progressing very nicely and, obviously, we’re looking at the draft requests for proposals that have come out.” hoffman did not say definitively that blue origin will submit a proposal for a lane 2 contract.  with regard to the development of new glenn, he said, “we’ve got more boosters, we’ve got three fairings. a lot of work is going on down at the  florida manufacturing complex .” “we’re on track for launch next year,” hoffman said. ',\n",
              " 'paris – to speed up access to earth observation data for millions of customers, esri is closely integrating its arcgis geographic mapping platform with microsoft azure space. “we’re putting the entire technology stack in azure space data centers,”  richard cooke, esri, imagery and remote sensing director, told  spacenews  at the world satellite business week conference here. “we are co-locating our technology by the antennas to reduce the latency, automate a lot of the post-processing and get to the meaningful data as quickly as possible.” microsoft made a series of  announcements  sept. 11, including partnerships with esri and  synthetaic . synthetaic, a startup that uses artificial intelligence to analyze geospatial data, announced a strategic partnership aug. 29 with microsoft. as part of the five-year deal, synthetaic will have access to extensive cloud compute resources.  synthetaic is integrating its technology with azure space to harness the “speed and versatility of ai to process geospatial, static and video imagery for a range of use cases,” including national security, disaster response, environmental and sustainability operations, synthetaic said in a  news release . azure space also added the planetary computer, a microsoft platform that combines multi-petabyte global datasets related to biodiversity and climate change with machine-learning tools. “think about the pc as a foundational data management toolset that allows users to manage geosptail data in the cloud in a standardized fashion,” said steve kitay, azure space senior director.  in addition, nasa langley research center, nasa goddard space flight center and kongsberg satellite services demonstrated rapid acquisition, processing and distribution of earth science data products by working with azure space. the nasa centers linked ksat and azure orbital ground stations with nasa and national oceanic and atmospheric organization earth-observation and weather satellites: terra, aqua, suomi national polar-orbiting partnership and noaa-20. the demonstration showed that processed data could reach customers within 25 minutes, according to the microsoft news release.  another azure orbital customer, muon space, launched its  first weather satellite  in june. “since we’re building constellations of remote sensing spacecraft with unique revisit, resolution and data latency capabilities, our ground station partner was a critical choice,” jim martz, muon vice president engineering, said in a statement. muon selected azure orbital ground station based on its capabilities and product roadmap.  ',\n",
              " 'san francisco – global satellite fleet operator intelsat announced an agreement sept. 12 with aalyria technologies to dramatically speed up satellite communications. “how do you create the capacity and capability of subsea cables but put them in space?” chris taylor, aalyria founder and ceo, asked at the world satellite business week conference here. “multi-terabit throughput from space is what we’re after. and intelsat believes in it.” as a first step, intelsat and aalyria plan to establish a bi-directional optical ground and space network in 2024 to transfer data at speeds of hundreds of gigabits per second. the network will rely on tightbeam, aalyria’s optical communications technology initially developed at google parent company, alphabet, and spacetime, aalyria network orchestration technology. accelerated data transfer is a key ingredient of the future space economy, taylor told  spacenews . “we can change the way data is moved on the planet, from the planet to the moon, to mars and beyond.”  the memorandum of understanding signed sept. 12 requires financial commitments from intelsat and aalyria in the optical communications technology. “aalyria’s groundbreaking technologies give us the opportunity to pursue highly secure connectivity at unprecedented speeds, opening up new frontiers in satellite communications,” bruno fromont, intelsat chief technology officer, said in a statement. “the intelsat-aalyria collaboration will enable enhanced mobile broadband connections and represents another step forward towards our next generation unifying network vision enabled by software-defined networking, 5g and multi-orbit operations.” intelsat is known for operating a fleet of geostationary communications satellites. the mclean, virginia-based company is considering  expanding its constellation to medium earth orbit . “we look at multi-orbit as being key to the longterm value proposition we bring to our customer sets,” said gregory ewert, intelsat vice president, business development. in addition to working with intelsat, livermore, california-based aalyria is demonstrating spacetime through the defense innovation unit’s  hybrid space architecture . hsa is designed to link commercial and government satellites with global, high-speed, secure data connections.  spacetime is a software platform to connect aircraft, ships and ground stations with satellites in various orbits. aalyria also has spacetime partnerships with  rivada space networks ,  anduril ,  leidos , and a tightbeam partnership with the  u.s. navy .  successful partnerships are based on relationships, science and a common vision for what’s possible, taylor said.  “we won the lottery with intelsat with regard to all of those,” taylor said. “with them deciding what form they will take as a multi-satellite operator, it’s the perfect vehicle onto which we can attach our own capabilities to support their businesses and to develop our own.”',\n",
              " 'paris — nasa and the other partners on the international space station have approved the crew of the third private astronaut mission by axiom space, scheduled to launch in early 2024. nasa and axiom space announced sept. 12 that they had finalized the crew for the ax-3 mission launching no earlier than january 2024. the mission will be commanded by michael lópez-alegría, a former nasa astronaut who also led the ax-1 mission to the iss in april 2022. the three customers are alper gezeravcı, walter villadei and marcus wandt. villadei, who will be pilot of ax-3, is an italian air force colonel who trained as a backup for the ax-2 mission and  flew on virgin galactic’s first commercial suborbital flight, galactic 01 , in june. gezeravcı, a mission specialist, is a turkish air force officer and wandt, a mission specialist and former air force officer from sweden, was selected as a reserve member of esa’s astronaut corps last november. all three customers had been linked to the upcoming axiom mission. the turkish government announced in april it selected gezeravcı as its first astronaut and had previously signed an agreement with axiom. villadei had trained with axiom for ax-2 with the expectation of going to space on a future mission. esa, working with sweden’s space agency,  announced an agreement with axiom in april for a private astronaut flight , and later named wandt as the astronaut who would go. “this crew is shifting the paradigm of how governments and space agencies access and reap the benefits of microgravity,” lópez-alegría said in a company statement. “the ax-3 mission will be transformational as it fosters partnerships outside the construct of the iss and positions european nations as pioneers of the emerging commercial space industry.” as with the first two axiom missions, ax-3 will launch on a spacex crew dragon spacecraft and will spend up to 14 days on the iss. axiom is also planning a fourth mission, ax-4, later in 2024. the missions are enabled by nasa’s low earth orbit commercialization policy, which allows for up to two private astronaut missions a year to the iss as precursors to both commercial modules axiom plans to add to the station as well as development of commercial space stations that will ultimately succeed the iss. “these commercial efforts continue to expand opportunity and access to microgravity research and discovery,” angela hart, manager of nasa’s commercial low earth orbit development program, said in a nasa statement. “each of these missions is a next step in building our shared future in low earth orbit.”',\n",
              " 'tampa, fla. — spacex and ses are pooling their broadband satellites to offer cruise operators an integrated service promising up to 3 gigabits per second (gbps) of capacity per ship. the ses cruise mpowered + starlink service would mostly use spacex’s low earth orbit network (leo) and satellites in medium earth orbit (meo) from ses. in northern and southern regions, apart from the poles where there is no service, ses vice president of product management for maritime products gregory martin said their joint offering would leverage its geostationary satellites. ses would sell and manage the multi-orbit service when it becomes operational later this year and spacex would get a cut of the sales, martin told  spacenews  in an interview.  the luxembourg-based operator is also providing software to optimize the data traffic, said martin, who used to manage satellite communications at royal caribbean, an ses customer that became  the first cruise line  to adopt starlink last year. he said ses serves five of the top six cruise lines, which are now either using or testing starlink services. starlink and ses can still independently sell standalone connectivity to the cruise market following the deal. but rather than choosing between ses and starlink, martin said he expects cruise operators “are going to have multiple connections off the ship” and “we want to help manage that, be a big part of that, and working together with starlink … we’re able to provide the best possible service.” the service comes in two tiers: pro at 1.5 gbps per ship and premium at 3 gbps. martin said there are currently only a handful of cruise ships with anything near 1.5 gbps, and in many cases the combined offering would enable them to double their throughput at a competitive price. there are currently no plans to develop a user terminal that could connect to starlink and ses. the pro tier requires 10 starlink high throughput flat terminals and premium needs 18, according to martin, and both tiers would need two to three terminals for ses in meo. in a separate interview with  spacenews , ses ceo ruy pinto said the operator is open to discussing replicating its partnership with spacex in “very selective opportunities, markets or geographies.”',\n",
              " 'tampa, fla. — swissto12 has raised about $28 million in debt to scale up a manufacturing business seeking to disrupt the geostationary market with much smaller satellites, the 3d printing specialist said sept. 13. investment bank ubs provided the working capital facility for the venture, which has also raised more than 50 million euros ($54 million) in venture capital funding since spinning out of a swiss university in 2011. after initially focusing on 3d-printed radio frequency components, the venture expanded into building entire satellites with the support of the european space agency. while not all of swissto12’s hummingsat satellite platform would be 3d-printed, the company plans to leverage its expertise in additive manufacturing to accelerate production, cut costs, and improve performance. hummingsat is about the size of a dishwasher and can be at least three times cheaper than typical commercial telecoms satellites in geostationary orbit (geo), according to swissto12, which are typically about 10 times bigger. the company hopes to meet demand for more localized services with satellites that have less capacity than their school bus-sized cousins, which have more room for transponders and power. intelsat became swissto12’s first customer last year for a hummingsat that  recently secured a 2026 launch with arianespace , alongside undisclosed co-passengers.  viasat-owned inmarsat, which also usually orders much larger geo satellites from more established manufacturers,  said in may  it had bought three hummingsats for a launch in 2026. in a sept. 13 news release announcing the working capital facility, swissto12 said it has more than 200 million euros in orders for hummingsats and its radio frequency product business combined.  new competitive landscape of the 10 orders announced so far this year for geo commercial communications satellites, six are to be built by small satellite ventures, including three by astranis of california. executives from traditional geostationary players cautiously welcomed the market entrants sept. 12 on a panel of manufacturers at euroconsult’s world satellite business conference in paris. chris banther, vice president of supply chain at lockheed martin, said the rise of these small satellite specialists comes as operators seek to diversify their suppliers — a trend he also sees in other areas of the market. “i think it’s actually pretty exciting,” said ryan reid, president of boeing satellite systems international, adding during the panel that it is a symptom of how much demand for broadband is outstripping supply.  “and i think these small geo systems allow … additional market creation and niche areas at a lower economic risk,” he said. stéphane vesval, senior vice president of sales and marketing for space systems at airbus defence and space, also does not see a shift in the geo market. “yes, [they] are addressing some unmet demand but we’re not seeing a direct impact on how the market is growing,” he said, pointing to  its recently announced contract  to build a more conventionally sized geo satellite for thaicom. “we are, of course, always careful and looking at the innovation,” vesval continued, “because even if some other [parts] are not directly competing [with] us, they are also very innovative. it keeps us on the edge and we keep moving forward.” marc-henri serre, executive vice president for telecoms at thales alenia space, said “clearly there are use [cases] that fit completely with this kind of product,” but the main challenge now “is how to have a product that works, has a good execution, and good delivery.” he said the industry is only “at the beginning of the story” and is still waiting to see if these products meet objectives. arcturus, the first satellite from astranis,  failed after launching to orbit  in april following an issue with its solar array drive assemblies.']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizamos"
      ],
      "metadata": {
        "id": "fIY_tyj1Qje4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "word_to_token = tokenizer.word_index"
      ],
      "metadata": {
        "id": "j3UXefouITYm"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui podemos ver el DataFrame tokenizado"
      ],
      "metadata": {
        "id": "9NTNp6LhQrI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def key_pair(num):\n",
        "    count=0\n",
        "    for key, value in word_to_token.items():\n",
        "        if count>=num: break\n",
        "        print(f''''{key:}': {value},''')\n",
        "        count +=1\n",
        "key_pair(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMEO4Kt9IVHS",
        "outputId": "c2f62424-41c8-4234-bcfa-ad5d48617f82"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'the': 1,\n",
            "'to': 2,\n",
            "'of': 3,\n",
            "'and': 4,\n",
            "'a': 5,\n",
            "'in': 6,\n",
            "'for': 7,\n",
            "'that': 8,\n",
            "'space': 9,\n",
            "'said': 10,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para ver algo de información, podemos saber cuantos pares de word-key tenemos."
      ],
      "metadata": {
        "id": "Wy8L-NM2Q0dy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_words = len(word_to_token)+1\n",
        "print(total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbQTOaGbIWc_",
        "outputId": "1f7572ab-4031-4fc2-d424-9dcfff494db0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a secuenciar, esto es convertir las oraciones a un valor numérico basado en los pares word-key que hemos sacado previamente."
      ],
      "metadata": {
        "id": "sY-VBE4cR1W5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "with strategy.scope():\n",
        "    for line in corpus:\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "        for i in range(1, len(token_list)):\n",
        "            n_gram_sequence = token_list[:i+1]\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "\n",
        "len(input_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUPC8t8hIX6t",
        "outputId": "82a80fc9-a33d-4c2d-cb97-ef5d7ae17117"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "815610"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wbdq4PHMCrC",
        "outputId": "4695975c-7566-4014-c90b-6ab37b927e40"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "815610"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences[:5]\n",
        "before = input_sequences[1]"
      ],
      "metadata": {
        "id": "EPq3TlZ2MFDu"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Necesitamos saber cual es la secuencia más grande."
      ],
      "metadata": {
        "id": "5N-uSap-SHL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = max(len(x) for x in input_sequences)\n",
        "print(max_seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQE71dANMYWY",
        "outputId": "95ef21b4-6542-4fe5-f8cf-a11b209b3b29"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora no todas las entradas tienen la misma longitud, por lo que vamos a hacer que tengan la misma longitud rellenando una matriz con ceros."
      ],
      "metadata": {
        "id": "3IeUGkI9SVGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_seq_len, padding = 'pre'))\n",
        "after = input_sequences[1]"
      ],
      "metadata": {
        "id": "H9CK2l7pMcsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Before: {before}')\n",
        "print(f'After: {after}')"
      ],
      "metadata": {
        "id": "r7y6qAAgMkb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features, labels = input_sequences[:, :-1], input_sequences[:, -1],"
      ],
      "metadata": {
        "id": "SeCleFBZMol8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convertimos a categorical"
      ],
      "metadata": {
        "id": "w22e_OF4T8je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "metadata": {
        "id": "PIT2mDiDMrat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nos quedamos con una pequeña porción de datos del DataFrame, en concreto con tan sólo el 5% de los datos."
      ],
      "metadata": {
        "id": "ZcqmG-HoUFFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    n = 0.05 # We are only taking a chunk of this huge dataset to fit it on the RAM\n",
        "    slice_size = int(len(features)*n)"
      ],
      "metadata": {
        "id": "Z-UpopNYMv9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo"
      ],
      "metadata": {
        "id": "AZtSML_3NCto"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos el modelo"
      ],
      "metadata": {
        "id": "tS3I3459UOqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_model():\n",
        "    tf.random.set_seed(42)\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(total_words, 100, input_length = max_seq_len-1)),\n",
        "    model.add(Bidirectional(LSTM(64, return_sequences = True))),\n",
        "    model.add(Bidirectional(LSTM(32))),\n",
        "    model.add(Dense(64, activation = 'relu')),\n",
        "    model.add(Dense(total_words, activation = 'softmax'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "qMaLZAeINEc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    model = generator_model()\n",
        "    model.compile(loss = 'categorical_crossentropy',\n",
        "                 optimizer = tf.keras.optimizers.Adam(learning_rate = 0.002),\n",
        "                 metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "zqS0894eNIGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "g_Xmg6SaNLAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "history = model.fit(features, labels, epochs = EPOCHS)"
      ],
      "metadata": {
        "id": "Bu1crV4BNNwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loss Accuracy Curve"
      ],
      "metadata": {
        "id": "2V82tiG7NS_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos generar las gráficas de la accuracy de la loss"
      ],
      "metadata": {
        "id": "mbo1OSpQUWHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_graph(history, string):\n",
        "    plt.plot(history.history[string])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(string)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "FacuyOfcNV6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_graph(history, 'accuracy')\n",
        "plot_graph(history, 'loss')"
      ],
      "metadata": {
        "id": "eDs2FqzjNbGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('test_generator.h5')"
      ],
      "metadata": {
        "id": "s_0uhdhKNenw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generación de texto"
      ],
      "metadata": {
        "id": "oiY8Mc0QNqQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probamos el modelo."
      ],
      "metadata": {
        "id": "tyZrRJ4ZUbmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_generator(string, num):\n",
        "    if len(string)==0:\n",
        "        print(\"Error: No word found\")\n",
        "        return\n",
        "    for _ in range(num):\n",
        "        token_list = tokenizer.texts_to_sequences([string])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_seq_len-1, padding = \"pre\")\n",
        "        probabilities = model.predict(token_list)\n",
        "        choice = np.random.choice([1,2,3])\n",
        "        predicted = np.argsort(probabilities, axis = -1)[0][-choice]\n",
        "        if predicted !=0:\n",
        "            generated_word = tokenizer.index_word[predicted]\n",
        "            string += \" \" + generated_word\n",
        "    print(string)"
      ],
      "metadata": {
        "id": "MklyTodgNs2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator(\"HawkEye 360 announced\", 20)"
      ],
      "metadata": {
        "id": "7F0px5CTOAie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos probado a ejecutar varias veces el notebook y no entendemos porque a veces si que se ejecuta y podemos ver cómo funciona nuestro modelo, y otras veces no termina de ejecutarse esta última parte debido a que gastamos toda la RAM que nos proporciona Collab de forma gratuita (12GB)."
      ],
      "metadata": {
        "id": "SeRDp0-oUfNY"
      }
    }
  ]
}